# jetracer_ros
A ROS package of the WaveShare JetRacer ROS AI Kit. An educational AI robot based on NVIDIA Jetson Nano.

http://www.waveshare.net/shop/JetRacer-ROS-AI-Kit.htm

http://www.waveshare.com/JetRacer-ROS-AI-Kit.htm

# 연구 배경
본 프로젝트는 제4회 국제 대학생 EV 자율주행 경진대회 Basic 1/10 부문 출전 및 수상을 목표로 시작했다. 하드웨어 구성은 JetRacer, Jetson Nano 보드를 직접 선정했으며, 실제 도로를 모사한 트랙 위에서 Camera, LiDAR, Odometry 센서 데이터를 기반으로 안정적인 주행을 구현해야 했다. 특히 A, B, C 각 구간마다 사용가능한 센서가 제한된다는 것, Jetson Nano처럼 성능이 제한된 환경에서도 센서 데이터를 빠르게 처리하고 차량을 제어할 수 있는 알고리즘 최적화가 핵심 과제였다. ROS 기반 시스템을 직접 구성하면서, 인지–판단–제어 전 과정을 구현하고 통합하는 경험을 쌓고자 했다.

# 연구 목적
대회 트랙을 완주할 수 있는 경량 ROS 기반 자율주행 시스템을 직접 설계하고 구현하는 것이 본 프로젝트의 핵심 목표였다. 각 구간별 특성에 맞춰 센서 기반 주행 알고리즘을 개발했다. 
- A구간: 카메라 영상을 이용한 차선 중심 추종 주행
- B구간: 2D LiDAR를 이용한 벽 감지 및 회피 주행
- C구간: Odometry 데이터를 활용한 SLAM 기반 목표 지점 주행

# 제안 방법
## 카메라 기반 차선 인식 주행 (A구역)
카메라 Calibration을 통해 렌즈 왜곡 보정 후, BEV 변환으로 원근 왜곡을 제거했다. 이후 HSV 색상 필터와 Sobel 필터를 결합해 다양한 조명 환경 변화에도 강건하게 차선을 검출하고, Sliding window 방식을 사용해 차선 픽셀을 추적하고, Quadratic function으로 피팅하여 차로의 중심을 산출했다. 차량의 현재 위치와 중심선 간의 오차를 기반으로 조향 제어를 수행함으로써 안정적인 차선 추종 주행을 구현했다.
<img width="962" height="128" alt="image" src="https://github.com/user-attachments/assets/69bb90d4-c667-44f7-8082-9929acd57faa" />
## LiDAR 기반 장애물 회피 주행 (B구역)
LiDAR 센서를 이용해 장애물을 감지하고 회피 주행을 수행했다. GMapping 기반 SLAM으로 맵을 구성하고, move_base 패키지를 활용해 전역 경로를 계획했다. 위치 정합 이후, 실시간 LiDAR 데이터를 활용한 장애물 회피 주행을 수행했다. 
<img width="1007" height="131" alt="image" src="https://github.com/user-attachments/assets/87c4af18-89a0-4b5e-9581-4d6fd65400bf" />
## Odometry 기반 정밀 위치 추정 주행 (C구역)
IMU의 Yaw Rate과 바퀴 Encoder의 속도 데이터를 칼만 필터로 융합해 차량의 방향과 이동 거리를 추정하였다. IMU의 고주파 노이즈를 제거하기 위해 Low-pass 필터를 적용하고, 필터 파라미터를 조정하여 Odometry 정확도를 향상시켰다.

# 연구 결과
개발한 알고리즘은 연습 환경에서 안정적으로 작동했으나, 본선에서는 조도 변화, 위치 오차, 파라미터 민감도 등 실환경 요소에 따라 성능 저하가 관찰됐다. 따라서 실시간 대응 전략의 필요성이 요구되었다. 
## 카메라 기반 차선 인식 주행
연습 주행 및 본선 1차에서는 안정적인 차선 검출과 완주를 기록했다. 2차 주행에서는 강한 햇빛 변화로 HSV 필터 감도가 낮아졌으며, 실시간 조건 변화에 적응하는 파라미터 조정의 필요성을 확인했다.
## LiDAR 기반 장애물 회피 주행
맵 기반 경로 생성과 장애물 인식은 정상적으로 작동했고, 연습 구간에서는 기대한 결과를 얻었다. 다만, 본선에서는 A 구간 종료 후 위치 오차가 누적되며 초기 정렬에 어려움이 있었고, 이에 따라 경로 계획이 제대로 실행되지 않았다. 시작 위치 변화에 유연하게 대응할 수 있는 로컬 회피 기반 구조의 보완이 요구되었다.
<img width="1156" height="148" alt="image" src="https://github.com/user-attachments/assets/4ccf2072-cb2f-48be-8397-663bb5659813" />
## Odometry 기반 정밀 위치 추정 주행
센서 융합을 통해 평균 오차 0.5m 이하의 거리 추정 정확도를 확보했고, 칼만 필터는 다양한 환경에서도 안정적인 추정을 유지했다. 다만, 주행 조건에 따라 파라미터 조정이 반복적으로 필요했으며, 이에 대한 자동화 방안이 향후 보완 과제로 남았다.

# 결론
## 1. 연구 결과 요약 및 의의
OpenCV 기반 컴퓨터 비전 기술과 LiDAR mapping으로 통제된 실내 환경에서 안정적인 자율주행을 구현하여, 기본적인 기술만으로 시스템 구축이 가능함을 확인할 수 있었다.
## 2. 연구의 한계점
실제 도로 환경과 유사한 야외 주행 시 햇빛 변화로 인한 HSV 필터 감도  변화로 차선 인식률이 저하되었고, Global Map 상의 차량 위치 추정에 영향이 있었다. 이는 다양한 광원 변화에 대한 강건함의 부족을 의미했다.
## 3. 후속 연구 제안: 강화 학습 기반의 자율주행 알고리즘 도입
rule-based에 기반한 현재의 접근법을 넘어 후속 연구로 강화 학습을 사용한 자율 주행 알고리즘 도입을 제안한다. 딥러닝 기반으로 수많은 주행 데이터를 학습한 알고리즘은 외부 환경 변화에 마주하더라도 강인한 판단력과 경험 기반의 제어를 통해 주행 성능의 완성도를 향상시키기에, 신뢰성 높은 자율주행 시스템을 구축하는 데 기여할 것으로 기대한다.
